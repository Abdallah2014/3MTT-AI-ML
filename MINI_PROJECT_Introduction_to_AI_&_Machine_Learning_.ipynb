{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWjIyuO+hwddhgbnD8ePcs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdallah2014/Hello-World/blob/master/MINI_PROJECT_Introduction_to_AI_%26_Machine_Learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i-drBn04uEw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDRIS IBRAHIM:\n",
        "FELLOW ID:FE/23/28360170\n",
        "Cohort 3"
      ],
      "metadata": {
        "id": "QAVKAA3n7TwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to AI and Machine Learning**\n",
        "\n",
        "This aim to provide an overview of introduce AI and machine learning (ML), various applications and types of ML systems, and data preprocessing techniques.\n",
        "\n",
        "1. **Course Overview**\n",
        "\n",
        "**Introduction to AI and Machine Learning:**\n",
        "\n",
        "•\tAn overview of the course content and objectives.\n",
        "\n",
        "•\tAn introduction to Artificial Intelligence (AI) and Machine Learning (ML).\n",
        "\n",
        "•\tCommon applications and the different types of ML systems.\n",
        "\n",
        "•\tData preprocessing techniques, including handling missing data, scaling, encoding, and splitting the dataset.\n",
        "\n",
        "2. **What is AI?**\n",
        "\n",
        "•\t**Artificial Intelligence (AI)**: The field dedicated to creating machines capable of performing tasks that typically require human intelligence. This includes areas such as decision making, problem-solving, language understanding, and perception.\n",
        "\n",
        "**What is Machine Learning?**\n",
        "\n",
        "•\t**Machine Learning (ML)**: A subset of AI that focuses on the development of algorithms that learn from data. Instead of being explicitly programmed for every task, ML systems can identify patterns and make predictions or decisions based on input data.\n",
        "\n",
        "3. **Applications and Types of ML Systems**\n",
        "\n",
        "**Applications of AI and ML**\n",
        "\n",
        "AI and ML have found applications in various domains, including:\n",
        "\n",
        "•\t**Computer Vision**: Image recognition, object detection, and facial recognition.\n",
        "\n",
        "•\t**Natural Language Processing (NLP)**:Language translation, sentiment analysis, and chatbots.\n",
        "\n",
        "•\t**Recommendation Systems**: Personalizing content and product recommendations.\n",
        "\n",
        "•\t**Healthcare**: Disease prediction, medical image analysis, and personalized treatment.\n",
        "\n",
        "•\t**Finance**: Fraud detection, algorithmic trading, and risk management.\n",
        "\n",
        "**Types of Machine Learning**\n",
        "\n",
        "ML can generally be divided into several categories:\n",
        "\n",
        "•\t**Supervised Learning**: Algorithms learn from labeled data. Example applications include regression and classification (e.g., spam detection, image classification).\n",
        "\n",
        "•\t**Unsupervised Learning**: Algorithms identify patterns or groupings in data without labeled outcomes. Techniques include clustering (e.g., customer segmentation) and dimensionality reduction.\n",
        "\n",
        "•\t**Reinforcement Learning**: Agents learn to make decisions by interacting with an environment, receiving rewards or penalties. This is common in robotics and game AI.\n",
        "\n",
        "4. **Data Preprocessing**\n",
        "\n",
        "Effective data preprocessing is a critical step in building robust ML models. Key steps include:\n",
        "\n",
        "•\t**Data Cleaning**: Handling missing values, removing duplicates, and correcting errors.\n",
        "\n",
        "•\t**Data Transformation**: Scaling features, encoding categorical variables, and normalizing data.\n",
        "\n",
        "•\t**Data Splitting**: Dividing the dataset into training and testing sets to validate model performance.\n",
        "\n",
        "Below is an example Python code snippet that demonstrates these preprocessing steps using iris dataset.\n"
      ],
      "metadata": {
        "id": "KAdY03Fx-mDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load a sample dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name='species')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(X.head())\n",
        "\n",
        "# Example: Data Cleaning\n",
        "# (For the Iris dataset, cleaning might not be necessary, but here's a conceptual step.)\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in dataset:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# Suppose we had a categorical feature, here's how you might encode it:\n",
        "# For demonstration, let's create a dummy categorical column\n",
        "X['dummy_cat'] = np.where(X['sepal length (cm)'] > 5.0, 'High', 'Low')\n",
        "\n",
        "# Define column transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Scale numerical features\n",
        "        ('num', StandardScaler(), iris.feature_names),\n",
        "        # Encode the dummy categorical feature\n",
        "        ('cat', OneHotEncoder(), ['dummy_cat'])\n",
        "    ])\n",
        "\n",
        "# Build a pipeline that first preprocesses the data\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "# Fit and transform the data\n",
        "X_preprocessed = pipeline.fit_transform(X)\n",
        "print(\"\\nPreprocessed feature shape:\", X_preprocessed.shape)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42)\n",
        "print(\"\\nTraining set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbWktTEF7NiW",
        "outputId": "7188e884-a5d8-4539-a479-19eae32c544d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Overview:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "\n",
            "Missing values in dataset:\n",
            "sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "dtype: int64\n",
            "\n",
            "Preprocessed feature shape: (150, 6)\n",
            "\n",
            "Training set size: (105, 6)\n",
            "Testing set size: (45, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "•\t**Data Loading**: We load the Iris dataset and convert it into a Pandas DataFrame for ease of use.\n",
        "\n",
        "•\t**Data Cleaning**: We check for missing values (none in this dataset) and create a dummy categorical feature for demonstration.\n",
        "\n",
        "•\t**Data Transformation**: Using ColumnTransformer, we scale numerical features and one-hot encode the categorical feature.\n",
        "\n",
        "•\t**Data Splitting**: The dataset is split into training and testing sets to prepare for model training.\n",
        "\n",
        "5. **Conclusion**\n",
        "\n",
        "This mini-project have:\n",
        "•\tProvided an overview of the course and introduced key AI/ML concepts.\n",
        "•\tDiscussed common applications and the main types of machine learning systems.\n",
        "•\tRefreshed essential data preprocessing techniques with a practical code example.\n"
      ],
      "metadata": {
        "id": "Y3LqeACDC3jL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUlcjxXD9vts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dnocV2HQ7QDd"
      }
    }
  ]
}